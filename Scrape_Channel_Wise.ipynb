{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dff751e",
   "metadata": {},
   "source": [
    "# Educational Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a53b19",
   "metadata": {},
   "source": [
    "# Scrape Krish Naik's Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebdfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask , render_template , request , jsonify\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from urllib.request import urlopen as urReq\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "final_data=[]\n",
    "df=pd.DataFrame()\n",
    "f = open('(83) Krish Naik - YouTube.html', encoding=\"utf-8\")\n",
    "content = f.read()\n",
    "soup=bs(content, \"html.parser\")\n",
    "data  = soup.find_all(\"body\")\n",
    "#data1 = data[0].find_all(\"script\")[13].string \n",
    "data2 = data[0].find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\", \"id\":\"details\"})\n",
    "\n",
    "i=0\n",
    "while 1:\n",
    "    title=data2[i].div.a.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    views=data2[i].div.div.div.find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\"})[1].span.text.replace(' views','')\n",
    "    url=data2[i].div.a['href']\n",
    "    \n",
    "    \n",
    "    \n",
    "    web = urllib.request.urlopen(url)\n",
    "    soup1 = bs(web.read(), 'html.parser')\n",
    "    data_url  = soup1.find_all(\"body\")\n",
    "    try:\n",
    "        #print(title,i,'try')\n",
    "        data_url1 = data_url[0].find_all(\"script\")[21].string \n",
    "        p1 = re.compile('var ytInitialData = (.*?);')\n",
    "        m1 = p1.match(data_url1)\n",
    "        stocks1 = json.loads(m1.groups()[0])\n",
    "        likes=stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][0]['videoPrimaryInfoRenderer']['videoActions']\\\n",
    "        ['menuRenderer']['topLevelButtons'][0]['toggleButtonRenderer']['defaultText']['accessibility']['accessibilityData']['label'].replace(' likes','')\n",
    "        comment_count=int(stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][2]['itemSectionRenderer']['contents'][0]\\\n",
    "        ['commentsEntryPointHeaderRenderer']['commentCount']['simpleText'])\n",
    "        i+=1\n",
    "\n",
    "        final_data.append(['Krish Naik',title,url,views,likes,comment_count,''])\n",
    "        \n",
    "    except:\n",
    "        #print(title,i,'except')\n",
    "        i+=1\n",
    "    #i+=1\n",
    "    if len(final_data)==50:\n",
    "        break\n",
    "        \n",
    "df = pd.DataFrame(final_data, columns=['Name','Title','URL','Views','Likes','Comment_Count','Downloadable_Link'])\n",
    "df.to_csv(\"Krish_Naik.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23ede83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "#get all videos together\n",
    "\n",
    "df1=pd.read_csv(\"Krish_Naik.csv\")\n",
    "for i in range(len(df1['URL'])):\n",
    "    yt = YouTube(df1['URL'].iloc[i])\n",
    "    t = yt.streams.filter(only_audio=True)\n",
    "    t[0].download()\n",
    "\n",
    "    gauth = GoogleAuth()\n",
    "    drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05382a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in os.listdir():\n",
    "    # List files with .py\n",
    "    if i.endswith(\".mp4\"):\n",
    "        l.append(i)\n",
    "#print(l[0])\n",
    "#itertate through every video and upload it\n",
    "upload_file_list = []\n",
    "for i in range(len(l)):\n",
    "    upload_file_list.append(l[i])\n",
    "\n",
    "# print(upload_file_list)\n",
    "for upload_file in upload_file_list:\n",
    "    #print(upload_file)\n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1b_qQzY6A299yDvUFLhOJmendYlW7VyTH'}]})\n",
    "    # Read file and set it as the content of this instance.\n",
    "    gfile.SetContentFile(upload_file)\n",
    "    gfile.Upload() # Upload the file.\n",
    "\n",
    "# for i in upload_file_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df12d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df1=pd.read_csv(\"Krish_Naik.csv\")\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "\n",
    "# Auto-iterate through all files in the root folder.\n",
    "file_list = drive.ListFile().GetList()\n",
    "file_list=file_list[:-1]\n",
    "#print(file_list)\n",
    "for file1 in file_list:\n",
    "    tp=(file1['title'][:-4])\n",
    "    ind=df1[df1['Title']==tp.translate(str.maketrans('', '', string.punctuation))].index.values\n",
    "    try:\n",
    "        df1.at[ind[0],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "        if len(ind)>1:\n",
    "            for j in range(len(ind)):\n",
    "                df1.at[ind[j],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "    except:\n",
    "        print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfa26c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Krish_Naik.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b386eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "for i in glob.glob(\"*.mp4\"):\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a651f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118f663",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c4b38",
   "metadata": {},
   "source": [
    "# Scrape Hitesh Choudhary's channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e713ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask , render_template , request , jsonify\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from urllib.request import urlopen as urReq\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "final_data=[]\n",
    "df=pd.DataFrame()\n",
    "f = open('(79) Hitesh Choudhary - YouTube.html', encoding=\"utf-8\")\n",
    "content = f.read()\n",
    "soup=bs(content, \"html.parser\")\n",
    "data  = soup.find_all(\"body\")\n",
    "#data1 = data[0].find_all(\"script\")[13].string \n",
    "data2 = data[0].find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\", \"id\":\"details\"})\n",
    "\n",
    "i=0\n",
    "while 1:\n",
    "    title=data2[i].div.a.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    views=data2[i].div.div.div.find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\"})[1].span.text.replace(' views','')\n",
    "    url=data2[i].div.a['href']\n",
    "    \n",
    "    \n",
    "    \n",
    "    web = urllib.request.urlopen(url)\n",
    "    soup1 = bs(web.read(), 'html.parser')\n",
    "    data_url  = soup1.find_all(\"body\")\n",
    "    try:\n",
    "        #print(title,i,'try')\n",
    "        data_url1 = data_url[0].find_all(\"script\")[21].string \n",
    "        p1 = re.compile('var ytInitialData = (.*?);')\n",
    "        m1 = p1.match(data_url1)\n",
    "        stocks1 = json.loads(m1.groups()[0])\n",
    "        likes=stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][0]['videoPrimaryInfoRenderer']['videoActions']\\\n",
    "        ['menuRenderer']['topLevelButtons'][0]['toggleButtonRenderer']['defaultText']['accessibility']['accessibilityData']['label'].replace(' likes','')\n",
    "        comment_count=int(stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][2]['itemSectionRenderer']['contents'][0]\\\n",
    "        ['commentsEntryPointHeaderRenderer']['commentCount']['simpleText'])\n",
    "        i+=1\n",
    "\n",
    "        final_data.append(['Hitesh Choudhary',title,url,views,likes,comment_count,''])\n",
    "        \n",
    "    except:\n",
    "        #print(title,i,'except')\n",
    "        i+=1\n",
    "    #i+=1\n",
    "    if len(final_data)==50:\n",
    "        break\n",
    "        \n",
    "df = pd.DataFrame(final_data, columns=['Name','Title','URL','Views','Likes','Comment_Count','Downloadable_Link'])\n",
    "df.to_csv(\"Hitesh_Choudhary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a64bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "#get all videos together\n",
    "\n",
    "df1=pd.read_csv(\"Hitesh_Choudhary.csv\")\n",
    "for i in range(len(df1['URL'])):\n",
    "    yt = YouTube(df1['URL'].iloc[i])\n",
    "    t = yt.streams.filter(only_audio=True)\n",
    "    t[0].download()\n",
    "\n",
    "    gauth = GoogleAuth()\n",
    "    drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "503f158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in os.listdir():\n",
    "    # List files with .py\n",
    "    if i.endswith(\".mp4\"):\n",
    "        l.append(i)\n",
    "#print(l[0])\n",
    "#itertate through every video and upload it\n",
    "upload_file_list = []\n",
    "for i in range(len(l)):\n",
    "    upload_file_list.append(l[i])\n",
    "\n",
    "# print(upload_file_list)\n",
    "for upload_file in upload_file_list:\n",
    "    #print(upload_file)\n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1NcwoMakldItg8djB2WRqG1PwsvsXObXk'}]})\n",
    "    # Read file and set it as the content of this instance.\n",
    "    gfile.SetContentFile(upload_file)\n",
    "    gfile.Upload() # Upload the file.\n",
    "\n",
    "# for i in upload_file_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a1d45f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df1=pd.read_csv(\"Hitesh_Choudhary.csv\")\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "\n",
    "# Auto-iterate through all files in the root folder.\n",
    "file_list = drive.ListFile().GetList()\n",
    "file_list=file_list[:-1]\n",
    "#print(file_list)\n",
    "for file1 in file_list:\n",
    "    tp=(file1['title'][:-4])\n",
    "    ind=df1[df1['Title']==tp.translate(str.maketrans('', '', string.punctuation))].index.values\n",
    "    try:\n",
    "        df1.at[ind[0],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "        if len(ind)>1:\n",
    "            for j in range(len(ind)):\n",
    "                df1.at[ind[j],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "    except:\n",
    "        print(\"Completed\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859546cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Hitesh_Choudhary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2dfa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "for i in glob.glob(\"*.mp4\"):\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39defeb",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a5099a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ed77f",
   "metadata": {},
   "source": [
    "# Scrape Telusko's Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48bb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask , render_template , request , jsonify\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from urllib.request import urlopen as urReq\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "final_data=[]\n",
    "df=pd.DataFrame()\n",
    "f = open('(80) Telusko - YouTube.html', encoding=\"utf-8\")\n",
    "content = f.read()\n",
    "soup=bs(content, \"html.parser\")\n",
    "data  = soup.find_all(\"body\")\n",
    "#data1 = data[0].find_all(\"script\")[13].string \n",
    "data2 = data[0].find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\", \"id\":\"details\"})\n",
    "\n",
    "i=0\n",
    "while 1:\n",
    "    title=data2[i].div.a.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    views=data2[i].div.div.div.find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\"})[1].span.text.replace(' views','')\n",
    "    url=data2[i].div.a['href']\n",
    "    \n",
    "    \n",
    "    \n",
    "    web = urllib.request.urlopen(url)\n",
    "    soup1 = bs(web.read(), 'html.parser')\n",
    "    data_url  = soup1.find_all(\"body\")\n",
    "    try:\n",
    "        #print(title,i,'try')\n",
    "        data_url1 = data_url[0].find_all(\"script\")[21].string \n",
    "        p1 = re.compile('var ytInitialData = (.*?);')\n",
    "        m1 = p1.match(data_url1)\n",
    "        stocks1 = json.loads(m1.groups()[0])\n",
    "        likes=stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][0]['videoPrimaryInfoRenderer']['videoActions']\\\n",
    "        ['menuRenderer']['topLevelButtons'][0]['toggleButtonRenderer']['defaultText']['accessibility']['accessibilityData']['label'].replace(' likes','')\n",
    "        comment_count=int(stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][2]['itemSectionRenderer']['contents'][0]\\\n",
    "        ['commentsEntryPointHeaderRenderer']['commentCount']['simpleText'])\n",
    "        i+=1\n",
    "\n",
    "        final_data.append(['Telusko',title,url,views,likes,comment_count,''])\n",
    "        \n",
    "    except:\n",
    "        #print(title,i,'except')\n",
    "        i+=1\n",
    "    #i+=1\n",
    "    if len(final_data)==50:\n",
    "        break\n",
    "        \n",
    "df = pd.DataFrame(final_data, columns=['Name','Title','URL','Views','Likes','Comment_Count','Downloadable_Link'])\n",
    "df.to_csv(\"Telusko.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9cad0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "#get all videos together\n",
    "\n",
    "df1=pd.read_csv(\"Telusko.csv\")\n",
    "for i in range(len(df1['URL'])):\n",
    "    yt = YouTube(df1['URL'].iloc[i])\n",
    "    t = yt.streams.filter(only_audio=True)\n",
    "    t[0].download()\n",
    "\n",
    "    gauth = GoogleAuth()\n",
    "    drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2caf10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Not possible\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "l=[]\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "for i in os.listdir():\n",
    "    # List files with .py\n",
    "    if i.endswith(\".mp4\"):\n",
    "        l.append(i)\n",
    "#print(l[0])\n",
    "#itertate through every video and upload it\n",
    "upload_file_list = []\n",
    "for i in range(len(l)):\n",
    "    upload_file_list.append(l[i])\n",
    "\n",
    "# print(upload_file_list)\n",
    "for upload_file in upload_file_list:\n",
    "    #print(upload_file)\n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1FsES78nPNcEActs506Mmnzanxz8iVFkw'}]})\n",
    "    # Read file and set it as the content of this instance.\n",
    "    gfile.SetContentFile(upload_file)\n",
    "    try:\n",
    "        gfile.Upload() # Upload the file.\n",
    "    except:\n",
    "        print(\"Not possible\")\n",
    "\n",
    "# for i in upload_file_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd92c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df1=pd.read_csv(\"Telusko.csv\")\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "\n",
    "# Auto-iterate through all files in the root folder.\n",
    "file_list = drive.ListFile().GetList()\n",
    "file_list=file_list[:-1]\n",
    "#print(file_list)\n",
    "for file1 in file_list:\n",
    "    tp=(file1['title'][:-4])\n",
    "    ind=df1[df1['Title']==tp.translate(str.maketrans('', '', string.punctuation))].index.values\n",
    "    try:\n",
    "        df1.at[ind[0],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "        if len(ind)>1:\n",
    "            for j in range(len(ind)):\n",
    "                df1.at[ind[j],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "    except:\n",
    "        print(\"Completed\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4257adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Telusko.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df66c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "for i in glob.glob(\"*.mp4\"):\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b13f9",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bdd79",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56107f0f",
   "metadata": {},
   "source": [
    "# Scrape MySirG's channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60d7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask , render_template , request , jsonify\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from urllib.request import urlopen as urReq\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "final_data=[]\n",
    "df=pd.DataFrame()\n",
    "f = open('(80) MySirG.com - YouTube.html', encoding=\"utf-8\")\n",
    "content = f.read()\n",
    "soup=bs(content, \"html.parser\")\n",
    "data  = soup.find_all(\"body\")\n",
    "#data1 = data[0].find_all(\"script\")[13].string \n",
    "data2 = data[0].find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\", \"id\":\"details\"})\n",
    "\n",
    "i=0\n",
    "while 1:\n",
    "    title=data2[i].div.a.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    views=data2[i].div.div.div.find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\"})[1].span.text.replace(' views','')\n",
    "    url=data2[i].div.a['href']\n",
    "    \n",
    "    \n",
    "    \n",
    "    web = urllib.request.urlopen(url)\n",
    "    soup1 = bs(web.read(), 'html.parser')\n",
    "    data_url  = soup1.find_all(\"body\")\n",
    "    try:\n",
    "        #print(title,i,'try')\n",
    "        data_url1 = data_url[0].find_all(\"script\")[21].string \n",
    "        p1 = re.compile('var ytInitialData = (.*?);')\n",
    "        m1 = p1.match(data_url1)\n",
    "        stocks1 = json.loads(m1.groups()[0])\n",
    "        likes=stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][0]['videoPrimaryInfoRenderer']['videoActions']\\\n",
    "        ['menuRenderer']['topLevelButtons'][0]['toggleButtonRenderer']['defaultText']['accessibility']['accessibilityData']['label'].replace(' likes','')\n",
    "        comment_count=int(stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][2]['itemSectionRenderer']['contents'][0]\\\n",
    "        ['commentsEntryPointHeaderRenderer']['commentCount']['simpleText'])\n",
    "        i+=1\n",
    "\n",
    "        final_data.append(['MySirG',title,url,views,likes,comment_count,''])\n",
    "        \n",
    "    except:\n",
    "        #print(title,i,'except')\n",
    "        i+=1\n",
    "    #i+=1\n",
    "    if len(final_data)==50:\n",
    "        break\n",
    "        \n",
    "df = pd.DataFrame(final_data, columns=['Name','Title','URL','Views','Likes','Comment_Count','Downloadable_Link'])\n",
    "df.to_csv(\"MySirG.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a34d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "#get all videos together\n",
    "\n",
    "df1=pd.read_csv(\"MySirG.csv\")\n",
    "for i in range(len(df1['URL'])):\n",
    "    yt = YouTube(df1['URL'].iloc[i])\n",
    "    t = yt.streams.filter(only_audio=True)\n",
    "    t[0].download()\n",
    "\n",
    "    gauth = GoogleAuth()\n",
    "    drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa301bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "l=[]\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "for i in os.listdir():\n",
    "    # List files with .py\n",
    "    if i.endswith(\".mp4\"):\n",
    "        l.append(i)\n",
    "#print(l[0])\n",
    "#itertate through every video and upload it\n",
    "upload_file_list = []\n",
    "for i in range(len(l)):\n",
    "    upload_file_list.append(l[i])\n",
    "\n",
    "# print(upload_file_list)\n",
    "for upload_file in upload_file_list:\n",
    "    #print(upload_file)\n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1P9KyrwEL-q_DjYOLQKC94L0V4LRnUbqL'}]})\n",
    "    # Read file and set it as the content of this instance.\n",
    "    gfile.SetContentFile(upload_file)\n",
    "    try:\n",
    "        gfile.Upload() # Upload the file.\n",
    "    except:\n",
    "        print(\"Not possible\")\n",
    "\n",
    "# for i in upload_file_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91a4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df1=pd.read_csv(\"MySirG.csv\")\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "\n",
    "# Auto-iterate through all files in the root folder.\n",
    "file_list = drive.ListFile().GetList()\n",
    "file_list=file_list[:-1]\n",
    "#print(file_list)\n",
    "for file1 in file_list:\n",
    "    tp=(file1['title'][:-4])\n",
    "    ind=df1[df1['Title']==tp.translate(str.maketrans('', '', string.punctuation))].index.values\n",
    "    try:\n",
    "        df1.at[ind[0],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "        if len(ind)>1:\n",
    "            for j in range(len(ind)):\n",
    "                df1.at[ind[j],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "    except:\n",
    "        print(\"Completed\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d4db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"MySirG.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46e6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "for i in glob.glob(\"*.mp4\"):\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577fa081",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68596f7e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36053c",
   "metadata": {},
   "source": [
    "# Vlogging Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916d861",
   "metadata": {},
   "source": [
    "# Scrape Sourav Joshi Vlogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec0754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask , render_template , request , jsonify\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from urllib.request import urlopen as urReq\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "final_data=[]\n",
    "df=pd.DataFrame()\n",
    "f = open('(108) Sourav Joshi Vlogs - YouTube.html', encoding=\"utf-8\")\n",
    "content = f.read()\n",
    "soup=bs(content, \"html.parser\")\n",
    "data  = soup.find_all(\"body\")\n",
    "#data1 = data[0].find_all(\"script\")[13].string \n",
    "data2 = data[0].find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\", \"id\":\"details\"})\n",
    "\n",
    "i=0\n",
    "while 1:\n",
    "    #print(i)\n",
    "    title=data2[i].div.a.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    views=data2[i].div.div.div.find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\"})[1].span.text.replace(' views','')\n",
    "    url=data2[i].div.a['href']\n",
    "    \n",
    "    \n",
    "    \n",
    "    web = urllib.request.urlopen(url)\n",
    "    soup1 = bs(web.read(), 'html.parser')\n",
    "    data_url  = soup1.find_all(\"body\")\n",
    "    try:\n",
    "        #print(title,i,'try')\n",
    "        data_url1 = data_url[0].find_all(\"script\")[21].string \n",
    "        p1 = re.compile('var ytInitialData = (.*?);')\n",
    "        m1 = p1.match(data_url1)\n",
    "        stocks1 = json.loads(m1.groups()[0])\n",
    "        likes=stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][0]['videoPrimaryInfoRenderer']['videoActions']\\\n",
    "        ['menuRenderer']['topLevelButtons'][0]['toggleButtonRenderer']['defaultText']['accessibility']['accessibilityData']['label'].replace(' likes','')\n",
    "        comment_count=(stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][2]['itemSectionRenderer']['contents'][0]\\\n",
    "        ['commentsEntryPointHeaderRenderer']['commentCount']['simpleText'])\n",
    "        i+=1\n",
    "\n",
    "        final_data.append(['Sourav Joshi Vlogs',title,url,views,likes,comment_count,''])\n",
    "        #print(final_data)\n",
    "    except:\n",
    "        #print('except')\n",
    "        i+=1\n",
    "    #i+=1\n",
    "    if len(final_data)==50:\n",
    "        break\n",
    "        \n",
    "df = pd.DataFrame(final_data, columns=['Name','Title','URL','Views','Likes','Comment_Count','Downloadable_Link'])\n",
    "df.to_csv(\"Sourav_Joshi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de4a85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "#get all videos together\n",
    "\n",
    "df1=pd.read_csv(\"Sourav_Joshi.csv\")\n",
    "for i in range(len(df1['URL'])):\n",
    "    yt = YouTube(df1['URL'].iloc[i])\n",
    "    t = yt.streams.filter(only_audio=True)\n",
    "    t[0].download()\n",
    "\n",
    "    gauth = GoogleAuth()\n",
    "    drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce1211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "l=[]\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "for i in os.listdir():\n",
    "    # List files with .py\n",
    "    if i.endswith(\".mp4\"):\n",
    "        l.append(i)\n",
    "#print(l[0])\n",
    "#itertate through every video and upload it\n",
    "upload_file_list = []\n",
    "for i in range(len(l)):\n",
    "    upload_file_list.append(l[i])\n",
    "\n",
    "# print(upload_file_list)\n",
    "for upload_file in upload_file_list:\n",
    "    #print(upload_file)\n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1PerEW0HLsrf-UPEjo_o6MCna3L3dSSa2'}]})\n",
    "    # Read file and set it as the content of this instance.\n",
    "    gfile.SetContentFile(upload_file)\n",
    "    try:\n",
    "        gfile.Upload() # Upload the file.\n",
    "    except:\n",
    "        print(\"Not possible\")\n",
    "\n",
    "# for i in upload_file_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71bc73c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df1=pd.read_csv(\"Sourav_Joshi.csv\")\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "\n",
    "# Auto-iterate through all files in the root folder.\n",
    "file_list = drive.ListFile().GetList()\n",
    "file_list=file_list[:-1]\n",
    "#print(file_list)\n",
    "for file1 in file_list:\n",
    "    tp=(file1['title'][:-4])\n",
    "    ind=df1[df1['Title']==tp.translate(str.maketrans('', '', string.punctuation))].index.values\n",
    "    try:\n",
    "        df1.at[ind[0],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "        if len(ind)>1:\n",
    "            for j in range(len(ind)):\n",
    "                df1.at[ind[j],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "    except:\n",
    "        print(\"Completed\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "966767fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Sourav_Joshi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34065ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "for i in glob.glob(\"*.mp4\"):\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0596c19a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50c80e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45f0f1",
   "metadata": {},
   "source": [
    "# Scrape Flying Beast channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96605260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask , render_template , request , jsonify\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from urllib.request import urlopen as urReq\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "final_data=[]\n",
    "df=pd.DataFrame()\n",
    "f = open('(109) Flying Beast - YouTube.html', encoding=\"utf-8\")\n",
    "content = f.read()\n",
    "soup=bs(content, \"html.parser\")\n",
    "data  = soup.find_all(\"body\")\n",
    "#data1 = data[0].find_all(\"script\")[13].string \n",
    "data2 = data[0].find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\", \"id\":\"details\"})\n",
    "\n",
    "i=0\n",
    "while 1:\n",
    "    #print(i)\n",
    "    title=data2[i].div.a.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    views=data2[i].div.div.div.find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\"})[1].span.text.replace(' views','')\n",
    "    url=data2[i].div.a['href']\n",
    "    \n",
    "    \n",
    "    \n",
    "    web = urllib.request.urlopen(url)\n",
    "    soup1 = bs(web.read(), 'html.parser')\n",
    "    data_url  = soup1.find_all(\"body\")\n",
    "    try:\n",
    "        #print(title,i,'try')\n",
    "        data_url1 = data_url[0].find_all(\"script\")[21].string \n",
    "        p1 = re.compile('var ytInitialData = (.*?);')\n",
    "        m1 = p1.match(data_url1)\n",
    "        stocks1 = json.loads(m1.groups()[0])\n",
    "        likes=stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][0]['videoPrimaryInfoRenderer']['videoActions']\\\n",
    "        ['menuRenderer']['topLevelButtons'][0]['toggleButtonRenderer']['defaultText']['accessibility']['accessibilityData']['label'].replace(' likes','')\n",
    "        comment_count=(stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][2]['itemSectionRenderer']['contents'][0]\\\n",
    "        ['commentsEntryPointHeaderRenderer']['commentCount']['simpleText'])\n",
    "        i+=1\n",
    "\n",
    "        final_data.append(['Flying Beast',title,url,views,likes,comment_count,''])\n",
    "        #print(final_data)\n",
    "    except:\n",
    "        #print('except')\n",
    "        i+=1\n",
    "    #i+=1\n",
    "    if len(final_data)==50:\n",
    "        break\n",
    "        \n",
    "df = pd.DataFrame(final_data, columns=['Name','Title','URL','Views','Likes','Comment_Count','Downloadable_Link'])\n",
    "df.to_csv(\"Flying_Beast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206137d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "#get all videos together\n",
    "\n",
    "df1=pd.read_csv(\"Flying_Beast.csv\")\n",
    "for i in range(len(df1['URL'])):\n",
    "    yt = YouTube(df1['URL'].iloc[i])\n",
    "    try:\n",
    "        t = yt.streams.filter(only_audio=True)\n",
    "        t[0].download()\n",
    "    except:\n",
    "        print(\"Video Unavailable\")\n",
    "\n",
    "    gauth = GoogleAuth()\n",
    "    drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2faa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "l=[]\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "for i in os.listdir():\n",
    "    # List files with .py\n",
    "    if i.endswith(\".mp4\"):\n",
    "        l.append(i)\n",
    "#print(l[0])\n",
    "#itertate through every video and upload it\n",
    "upload_file_list = []\n",
    "for i in range(len(l)):\n",
    "    upload_file_list.append(l[i])\n",
    "\n",
    "# print(upload_file_list)\n",
    "for upload_file in upload_file_list:\n",
    "    #print(upload_file)\n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1Lu5ONmD47C6ECYD08OW40Bop25_Sl2-h'}]})\n",
    "    # Read file and set it as the content of this instance.\n",
    "    gfile.SetContentFile(upload_file)\n",
    "    try:\n",
    "        gfile.Upload() # Upload the file.\n",
    "    except:\n",
    "        print(\"Not possible\")\n",
    "\n",
    "# for i in upload_file_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4adba650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df1=pd.read_csv(\"Flying_Beast.csv\")\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "\n",
    "# Auto-iterate through all files in the root folder.\n",
    "file_list = drive.ListFile().GetList()\n",
    "file_list=file_list[:-1]\n",
    "#print(file_list)\n",
    "for file1 in file_list:\n",
    "    tp=(file1['title'][:-4])\n",
    "    ind=df1[df1['Title']==tp.translate(str.maketrans('', '', string.punctuation))].index.values\n",
    "    try:\n",
    "        df1.at[ind[0],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "        if len(ind)>1:\n",
    "            for j in range(len(ind)):\n",
    "                df1.at[ind[j],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "    except:\n",
    "        print(\"Completed\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b523aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Flying_Beast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d045e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "for i in glob.glob(\"*.mp4\"):\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122b220",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d09083",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ebc4a",
   "metadata": {},
   "source": [
    "# Scrape Mumbiker Nikhil Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed35da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask , render_template , request , jsonify\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from urllib.request import urlopen as urReq\n",
    "import requests\n",
    "import urllib\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "final_data=[]\n",
    "df=pd.DataFrame()\n",
    "f = open('(109) Mumbiker Nikhil - YouTube.html', encoding=\"utf-8\")\n",
    "content = f.read()\n",
    "soup=bs(content, \"html.parser\")\n",
    "data  = soup.find_all(\"body\")\n",
    "#data1 = data[0].find_all(\"script\")[13].string \n",
    "data2 = data[0].find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\", \"id\":\"details\"})\n",
    "\n",
    "i=0\n",
    "while 1:\n",
    "    #print(i)\n",
    "    title=data2[i].div.a.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    views=data2[i].div.div.div.find_all(\"div\", {\"class\":\"style-scope ytd-grid-video-renderer\"})[1].span.text.replace(' views','')\n",
    "    url=data2[i].div.a['href']\n",
    "    \n",
    "    \n",
    "    \n",
    "    web = urllib.request.urlopen(url)\n",
    "    soup1 = bs(web.read(), 'html.parser')\n",
    "    data_url  = soup1.find_all(\"body\")\n",
    "    try:\n",
    "        #print(title,i,'try')\n",
    "        data_url1 = data_url[0].find_all(\"script\")[21].string \n",
    "        p1 = re.compile('var ytInitialData = (.*?);')\n",
    "        m1 = p1.match(data_url1)\n",
    "        stocks1 = json.loads(m1.groups()[0])\n",
    "        likes=stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][0]['videoPrimaryInfoRenderer']['videoActions']\\\n",
    "        ['menuRenderer']['topLevelButtons'][0]['toggleButtonRenderer']['defaultText']['accessibility']['accessibilityData']['label'].replace(' likes','')\n",
    "        comment_count=(stocks1['contents']['twoColumnWatchNextResults']['results']['results']['contents'][2]['itemSectionRenderer']['contents'][0]\\\n",
    "        ['commentsEntryPointHeaderRenderer']['commentCount']['simpleText'])\n",
    "        i+=1\n",
    "\n",
    "        final_data.append(['Mumbiker Nikhil',title,url,views,likes,comment_count,''])\n",
    "        #print(final_data)\n",
    "    except:\n",
    "        #print('except')\n",
    "        i+=1\n",
    "    #i+=1\n",
    "    if len(final_data)==50:\n",
    "        break\n",
    "        \n",
    "df = pd.DataFrame(final_data, columns=['Name','Title','URL','Views','Likes','Comment_Count','Downloadable_Link'])\n",
    "df.to_csv(\"Mumbiker_Nikhil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734af8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "#get all videos together\n",
    "\n",
    "df1=pd.read_csv(\"Mumbiker_Nikhil.csv\")\n",
    "for i in range(len(df1['URL'])):\n",
    "    yt = YouTube(df1['URL'].iloc[i])\n",
    "    try:\n",
    "        t = yt.streams.filter(only_audio=True)\n",
    "        t[0].download()\n",
    "    except:\n",
    "        print(\"Video Unavailable\")\n",
    "\n",
    "    gauth = GoogleAuth()\n",
    "    drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517769f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "l=[]\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "for i in os.listdir():\n",
    "    # List files with .py\n",
    "    if i.endswith(\".mp4\"):\n",
    "        l.append(i)\n",
    "#print(l[0])\n",
    "#itertate through every video and upload it\n",
    "upload_file_list = []\n",
    "for i in range(len(l)):\n",
    "    upload_file_list.append(l[i])\n",
    "\n",
    "# print(upload_file_list)\n",
    "for upload_file in upload_file_list:\n",
    "    #print(upload_file)\n",
    "    gfile = drive.CreateFile({'parents': [{'id': '1tr3GtYAUDvEInVzGdvh-z6n41XXj85Aq'}]})\n",
    "    # Read file and set it as the content of this instance.\n",
    "    gfile.SetContentFile(upload_file)\n",
    "    try:\n",
    "        gfile.Upload() # Upload the file.\n",
    "    except:\n",
    "        print(\"Not possible\")\n",
    "\n",
    "# for i in upload_file_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d18d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=35777712773-k5r0cfuc12uvn5popb9lhjdmp83had9i.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import requests\n",
    "from pytube import YouTube\n",
    "import time\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df1=pd.read_csv(\"Mumbiker_Nikhil.csv\")\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "\n",
    "# Auto-iterate through all files in the root folder.\n",
    "file_list = drive.ListFile().GetList()\n",
    "file_list=file_list[:-1]\n",
    "#print(file_list)\n",
    "for file1 in file_list:\n",
    "    tp=(file1['title'][:-4])\n",
    "    ind=df1[df1['Title']==tp.translate(str.maketrans('', '', string.punctuation))].index.values\n",
    "    try:\n",
    "        df1.at[ind[0],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "        if len(ind)>1:\n",
    "            for j in range(len(ind)):\n",
    "                df1.at[ind[j],'Downloadable_Link']='https://drive.google.com/file/d/' + str(file1['id']) + '/view?usp=sharing'\n",
    "    except:\n",
    "        print(\"Completed\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eccc9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Mumbiker_Nikhil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b122edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "for i in glob.glob(\"*.mp4\"):\n",
    "    os.remove(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
