{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1520a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44af9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "comment_yt=[]\n",
    "commenter_name=[]\n",
    "df=pd.read_csv(\"Krish_Naik.csv\")\n",
    "for m in range(50):\n",
    "    with Chrome() as driver:\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        driver.get(df[\"URL\"].iloc[m])\n",
    "\n",
    "        for item in range(4): #by increasing the highest range you can get more content\n",
    "            wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "            time.sleep(3)\n",
    "        #print(wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))))\n",
    "        for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #content-text\"))):\n",
    "            comment_yt.append(comment.text)\n",
    "            #print(comment.text)\n",
    "\n",
    "        for i in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))):\n",
    "            count+=1\n",
    "            commenter_name.append(i.text)\n",
    "            #print(i.text)\n",
    "        #print(count-1)\n",
    "\n",
    "    final_list=[]\n",
    "    for k,j in zip(comment_yt,commenter_name):\n",
    "        final_list.append([k,j,df['Title'].iloc[m]])\n",
    "\n",
    "    \n",
    "    j=json.dumps([{\"krish\": val} for val in final_list])\n",
    "    json_object = json.loads(j)\n",
    "#     json_object.to_json(\"hfkf.json\")\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    def write_json(new_data, filename='Krish_json.json'):\n",
    "        with open(filename,'r+') as file:\n",
    "              # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[\"video_details\"].append(new_data)\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 4)\n",
    "\n",
    "    # python object to be appended\n",
    "#     y = {\"emp_name\":\"Nikhil\",\n",
    "#          \"email\": \"nikhil@geeksforgeeks.org\",\n",
    "#          \"job_profile\": \"Full Time\"\n",
    "#         }\n",
    "\n",
    "    write_json(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45083074",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "comment_yt=[]\n",
    "commenter_name=[]\n",
    "df=pd.read_csv(\"Hitesh_Choudhary.csv\")\n",
    "for m in range(50):\n",
    "    with Chrome() as driver:\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        driver.get(df[\"URL\"].iloc[m])\n",
    "\n",
    "        for item in range(2): #by increasing the highest range you can get more content\n",
    "            wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "            time.sleep(3)\n",
    "        #print(wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))))\n",
    "        for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #content-text\"))):\n",
    "            comment_yt.append(comment.text)\n",
    "            #print(comment.text)\n",
    "\n",
    "        for i in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))):\n",
    "            count+=1\n",
    "            commenter_name.append(i.text)\n",
    "            #print(i.text)\n",
    "        #print(count-1)\n",
    "\n",
    "    final_list=[]\n",
    "    for k,j in zip(comment_yt,commenter_name):\n",
    "        final_list.append([k,j,df['Title'].iloc[m]])\n",
    "\n",
    "    \n",
    "    j=json.dumps([{\"Hitesh\": val} for val in final_list])\n",
    "    json_object = json.loads(j)\n",
    "#     json_object.to_json(\"hfkf.json\")\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    def write_json(new_data, filename='Hitesh_json.json'):\n",
    "        with open(filename,'r+') as file:\n",
    "              # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[\"video_details\"].append(new_data)\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 4)\n",
    "\n",
    "    # python object to be appended\n",
    "#     y = {\"emp_name\":\"Nikhil\",\n",
    "#          \"email\": \"nikhil@geeksforgeeks.org\",\n",
    "#          \"job_profile\": \"Full Time\"\n",
    "#         }\n",
    "\n",
    "    write_json(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311cb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "comment_yt=[]\n",
    "commenter_name=[]\n",
    "df=pd.read_csv(\"Telusko.csv\")\n",
    "for m in range(50):\n",
    "    with Chrome() as driver:\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        driver.get(df[\"URL\"].iloc[m])\n",
    "\n",
    "        for item in range(2): #by increasing the highest range you can get more content\n",
    "            wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "            time.sleep(3)\n",
    "        #print(wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))))\n",
    "        for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #content-text\"))):\n",
    "            comment_yt.append(comment.text)\n",
    "            #print(comment.text)\n",
    "\n",
    "        for i in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))):\n",
    "            count+=1\n",
    "            commenter_name.append(i.text)\n",
    "            #print(i.text)\n",
    "        #print(count-1)\n",
    "\n",
    "    final_list=[]\n",
    "    for k,j in zip(comment_yt,commenter_name):\n",
    "        final_list.append([k,j,df['Title'].iloc[m]])\n",
    "\n",
    "    \n",
    "    j=json.dumps([{\"Telusko\": val} for val in final_list])\n",
    "    json_object = json.loads(j)\n",
    "#     json_object.to_json(\"hfkf.json\")\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    def write_json(new_data, filename='Telusko_json.json'):\n",
    "        with open(filename,'r+') as file:\n",
    "              # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[\"video_details\"].append(new_data)\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 4)\n",
    "\n",
    "    # python object to be appended\n",
    "#     y = {\"emp_name\":\"Nikhil\",\n",
    "#          \"email\": \"nikhil@geeksforgeeks.org\",\n",
    "#          \"job_profile\": \"Full Time\"\n",
    "#         }\n",
    "\n",
    "    write_json(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a710b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "comment_yt=[]\n",
    "commenter_name=[]\n",
    "df=pd.read_csv(\"MySirG.csv\")\n",
    "for m in range(50):\n",
    "    with Chrome() as driver:\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        driver.get(df[\"URL\"].iloc[m])\n",
    "\n",
    "        for item in range(2): #by increasing the highest range you can get more content\n",
    "            wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "            time.sleep(3)\n",
    "        #print(wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))))\n",
    "        for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #content-text\"))):\n",
    "            comment_yt.append(comment.text)\n",
    "            #print(comment.text)\n",
    "\n",
    "        for i in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))):\n",
    "            count+=1\n",
    "            commenter_name.append(i.text)\n",
    "            #print(i.text)\n",
    "        #print(count-1)\n",
    "\n",
    "    final_list=[]\n",
    "    for k,j in zip(comment_yt,commenter_name):\n",
    "        final_list.append([k,j,df['Title'].iloc[m]])\n",
    "\n",
    "    \n",
    "    j=json.dumps([{\"MySirG\": val} for val in final_list])\n",
    "    json_object = json.loads(j)\n",
    "#     json_object.to_json(\"hfkf.json\")\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    def write_json(new_data, filename='MySirG_json.json'):\n",
    "        with open(filename,'r+') as file:\n",
    "              # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[\"video_details\"].append(new_data)\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 4)\n",
    "\n",
    "    # python object to be appended\n",
    "#     y = {\"emp_name\":\"Nikhil\",\n",
    "#          \"email\": \"nikhil@geeksforgeeks.org\",\n",
    "#          \"job_profile\": \"Full Time\"\n",
    "#         }\n",
    "\n",
    "    write_json(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578db491",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "comment_yt=[]\n",
    "commenter_name=[]\n",
    "df=pd.read_csv(\"Sourav_Joshi.csv\")\n",
    "for m in range(50):\n",
    "    with Chrome() as driver:\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        driver.get(df[\"URL\"].iloc[m])\n",
    "\n",
    "        for item in range(1): #by increasing the highest range you can get more content\n",
    "            wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "            time.sleep(3)\n",
    "        #print(wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))))\n",
    "        for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #content-text\"))):\n",
    "            comment_yt.append(comment.text)\n",
    "            #print(comment.text)\n",
    "\n",
    "        for i in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))):\n",
    "            count+=1\n",
    "            commenter_name.append(i.text)\n",
    "            #print(i.text)\n",
    "        #print(count-1)\n",
    "\n",
    "    final_list=[]\n",
    "    for k,j in zip(comment_yt,commenter_name):\n",
    "        final_list.append([k,j,df['Title'].iloc[m]])\n",
    "\n",
    "    \n",
    "    j=json.dumps([{\"Sourav\": val} for val in final_list])\n",
    "    json_object = json.loads(j)\n",
    "#     json_object.to_json(\"hfkf.json\")\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    def write_json(new_data, filename='SouravJoshi_json.json'):\n",
    "        with open(filename,'r+') as file:\n",
    "              # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[\"video_details\"].append(new_data)\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 4)\n",
    "\n",
    "    # python object to be appended\n",
    "#     y = {\"emp_name\":\"Nikhil\",\n",
    "#          \"email\": \"nikhil@geeksforgeeks.org\",\n",
    "#          \"job_profile\": \"Full Time\"\n",
    "#         }\n",
    "\n",
    "    write_json(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648a0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "comment_yt=[]\n",
    "commenter_name=[]\n",
    "df=pd.read_csv(\"Flying_Beast.csv\")\n",
    "for m in range(50):\n",
    "    with Chrome() as driver:\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        driver.get(df[\"URL\"].iloc[m])\n",
    "\n",
    "        for item in range(1): #by increasing the highest range you can get more content\n",
    "            wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "            time.sleep(3)\n",
    "        #print(wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))))\n",
    "        for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #content-text\"))):\n",
    "            comment_yt.append(comment.text)\n",
    "            #print(comment.text)\n",
    "\n",
    "        for i in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))):\n",
    "            count+=1\n",
    "            commenter_name.append(i.text)\n",
    "            #print(i.text)\n",
    "        #print(count-1)\n",
    "\n",
    "    final_list=[]\n",
    "    for k,j in zip(comment_yt,commenter_name):\n",
    "        final_list.append([k,j,df['Title'].iloc[m]])\n",
    "\n",
    "    \n",
    "    j=json.dumps([{\"Flying\": val} for val in final_list])\n",
    "    json_object = json.loads(j)\n",
    "#     json_object.to_json(\"hfkf.json\")\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    def write_json(new_data, filename='FlyingBeast_json.json'):\n",
    "        with open(filename,'r+') as file:\n",
    "              # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[\"video_details\"].append(new_data)\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 4)\n",
    "\n",
    "    # python object to be appended\n",
    "#     y = {\"emp_name\":\"Nikhil\",\n",
    "#          \"email\": \"nikhil@geeksforgeeks.org\",\n",
    "#          \"job_profile\": \"Full Time\"\n",
    "#         }\n",
    "\n",
    "    write_json(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afac9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "comment_yt=[]\n",
    "commenter_name=[]\n",
    "df=pd.read_csv(\"Mumbiker_Nikhil.csv\")\n",
    "for m in range(50):\n",
    "    with Chrome() as driver:\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        driver.get(df[\"URL\"].iloc[m])\n",
    "\n",
    "        for item in range(1): #by increasing the highest range you can get more content\n",
    "            wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "            time.sleep(3)\n",
    "        #print(wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))))\n",
    "        for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #content-text\"))):\n",
    "            comment_yt.append(comment.text)\n",
    "            #print(comment.text)\n",
    "\n",
    "        for i in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#comment #author-text > span\"))):\n",
    "            count+=1\n",
    "            commenter_name.append(i.text)\n",
    "            #print(i.text)\n",
    "        #print(count-1)\n",
    "\n",
    "    final_list=[]\n",
    "    for k,j in zip(comment_yt,commenter_name):\n",
    "        final_list.append([k,j,df['Title'].iloc[m]])\n",
    "\n",
    "    \n",
    "    j=json.dumps([{\"Mumbiker\": val} for val in final_list])\n",
    "    json_object = json.loads(j)\n",
    "#     json_object.to_json(\"hfkf.json\")\n",
    "    #print(j)\n",
    "    \n",
    "    \n",
    "    def write_json(new_data, filename='Mumbiker_json.json'):\n",
    "        with open(filename,'r+') as file:\n",
    "              # First we load existing data into a dict.\n",
    "            file_data = json.load(file)\n",
    "            # Join new_data with file_data inside emp_details\n",
    "            file_data[\"video_details\"].append(new_data)\n",
    "            # Sets file's current position at offset.\n",
    "            file.seek(0)\n",
    "            # convert back to json.\n",
    "            json.dump(file_data, file, indent = 4)\n",
    "\n",
    "    # python object to be appended\n",
    "#     y = {\"emp_name\":\"Nikhil\",\n",
    "#          \"email\": \"nikhil@geeksforgeeks.org\",\n",
    "#          \"job_profile\": \"Full Time\"\n",
    "#         }\n",
    "\n",
    "    write_json(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a173e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [\n",
    "    {\"name\": 'alex',\n",
    "       \"last_name\": 'leda'\n",
    "     },\n",
    "    { \"name\": 'john',\n",
    "       \"last_name\": 'parsons'\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8483d28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('name', 'alex')\n",
      "('last_name', 'leda')\n",
      "('name', 'john')\n",
      "('last_name', 'parsons')\n"
     ]
    }
   ],
   "source": [
    "for i in my_list:\n",
    "    for j in i.items():\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac3c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
